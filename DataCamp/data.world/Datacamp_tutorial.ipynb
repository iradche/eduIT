{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# data.world datacamp tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> #### Setup  \n",
    "\n",
    "> Before running data.world notebooks for the first time, you'll need to:  \n",
    "1. Install data.world's Python package, including optional `pandas` dependencies: \n",
    "```shell\n",
    "pip install datadotworld[pandas]\n",
    "```\n",
    "1. Obtain an API access token at https://data.world/settings/advanced\n",
    "1. Store API access token using the `dw` command-line tool: \n",
    "```shell\n",
    "dw configure\n",
    "```\n",
    "\n",
    "> Once your environment is set up, these steps do not need to be repeated for other data.world notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import datadotworld module and pp.pprint\n",
    "\n",
    "import datadotworld as dw\n",
    "import os\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib for plots\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load_dataset examples\n",
    "\n",
    "dataset = dw.load_dataset('https://data.world/stephen-hoover/chicago-city-council-votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# describe examples: describe dataset\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# describe examples: describe specific dataset resource\n",
    "\n",
    "dataset.describe('alderman_votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accessing the data\n",
    "## After loading a dataset object, you can access the data via: `raw_data`, `tables`, or `dataframes`.\n",
    "## Each of these returns a dictionary of values: `bytes`, `list` and `pandas.DataFrame` objects, respectively.\n",
    "\n",
    "votes_dataframe = dataset.dataframes['alderman_votes']\n",
    "votes_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Working with multiple datasets\n",
    "\n",
    "# Load two datasets from data.world that you'd like to merge:\n",
    "int_dataset = dw.load_dataset('https://data.world/jonloyens/intermediate-data-world')\n",
    "fipsCodes_dataset = dw.load_dataset('https://data.world/uscensusbureau/fips-state-codes')\n",
    "\n",
    "# Create two dataframes\n",
    "police_shootings = int_dataset.dataframes['fatal_police_shootings_data']\n",
    "state_abbrvs = fipsCodes_dataset.dataframes['statesfipscodes']\n",
    "\n",
    "## Merge the two datasets together on the state and stusab fields:\n",
    "merged_dataframe = police_shootings.merge(state_abbrvs, how = 'left', left_on = 'state', right_on='stusab')\n",
    "\n",
    "## Create a 'citystate' column in the merged_dataframe dataframe with the format `city, state_name`:\n",
    "merged_dataframe[\"citystate\"] = merged_dataframe[\"city\"] + \", \" + merged_dataframe[\"state_name\"]\n",
    "\n",
    "## Print head of merged dataframe\n",
    "pp.pprint(merged_dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Querying data.world via SDK\n",
    "## Query using SQL or SPARQL query languages. SQL is default, or add `query_type='sparql'` as a parameter for SPARQL. \n",
    "## The `query()` method gives you access to three properties to access the resulting data: `raw_data`, `table`, and `dataframe`.\n",
    "\n",
    "# SQL\n",
    "\n",
    "## Single table query exercise\n",
    "\n",
    "# Define query string\n",
    "sql_query = \"SELECT * FROM `unhcr_all` WHERE Year = 2010\"\n",
    "\n",
    "# Query table, passing query string as parameter\n",
    "query2010 = dw.query('https://data.world/nrippner/refugee-host-nations', sql_query)\n",
    "\n",
    "# Create dataframe using dataframe property\n",
    "unhcr2010 = query2010.dataframe\n",
    "\n",
    "# Print first 5 rows of results\n",
    "unhcr2010.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SQL\n",
    "\n",
    "## Multi-table join exercise\n",
    "\n",
    "# Define query string. Note that secondary table and fields are explicitly referenced using dataset key (ownerid/tableid)\n",
    "sql_query = \"SELECT state, count(fmid) as count, Avg(obesity.Value) as obesityAvg FROM Export LEFT JOIN health.`obesity-by-state-2014`.`adult_obese` as obesity ON state = obesity.location GROUP BY state ORDER BY count desc\"\n",
    "\n",
    "# Query 'local' table, passing query string as parameter\n",
    "queryResults = dw.query('https://data.world/agriculture/national-farmers-markets', sql_query)\n",
    "\n",
    "# Create dataframe using dataframe property\n",
    "stateStats = queryResults.dataframe\n",
    "\n",
    "# Plot results on state\n",
    "stateStats.plot(x='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SPARQL\n",
    "## Learn SPARQL using our tutorial at https://docs.data.world/documentation/api/sparql.html\n",
    "\n",
    "# Define query string\n",
    "sparql_query = \"PREFIX GOT: <https://tutorial.linked.data.world/d/sparqltutorial/> SELECT ?FName ?LName WHERE {?person GOT:col-got-house \\\"Stark\\\" . ?person GOT:col-got-fname ?FName . ?person GOT:col-got-lname ?LName .}\"\n",
    "\n",
    "# Query table, passing query string and `query_type` as parameters\n",
    "queryResults = dw.query('http://data.world/tutorial/sparqltutorial', sparql_query, query_type='sparql')\n",
    "\n",
    "# Create dataframe using dataframe property\n",
    "houseStark = queryResults.dataframe\n",
    "\n",
    "# Print first 5 rows of results\n",
    "pp.pprint(houseStark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Advanced SDK Functionality\n",
    "\n",
    "The data.world Python SDK includes a variety of API wrappers, available via the `ApiClient` class, that let you create, replace, update, and delete a dataset. In this section, we’ll walk through a few common tasks:\n",
    "\n",
    "- Use `api_client()` to get an instance of the `ApiClient`\n",
    "- Create a dataset\n",
    "- Add a file from a dataframe: we’ll write to a local csv and the upload the file\n",
    "- Add a file from a source URL: this is an easy way to add external data to your dataset and keep it up to date. We’ll use a file from GitHub as an example, but you can use any URL source that points to a file.\n",
    "- Sync the dataset: this simple call reloads any files with a source URL, to ensure the latest version.\n",
    "- Update the dataset: after creating a dataset, use `update_dataset` to change attirbutes like description, summary or tags.\n",
    "\n",
    "Use `help(api_client)` to learn more about each available function or see the full [data.world API documentation](https://docs.data.world/documentation/api/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of the ApiClient using `api_client()`\n",
    "api_client = dw.api_client()\n",
    "\n",
    "# See api_client documentation\n",
    "help(api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset using create_dataset method. \n",
    "\n",
    "# Replace the < > items with your username and desired dataset title. Visibility can be changed to 'OPEN' if you choose.\n",
    "api_client.create_dataset(owner_id=\"<YOUR_USERNAME>\", title=\"<DATASET_TITLE>\", visibility='PRIVATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write a dataframe to a local file and upload to dataset\n",
    "\n",
    "# Create dataframe\n",
    "police_shootings = dw.load_dataset('https://data.world/jonloyens/intermediate-data-world').dataframes['fatal_police_shootings_data']\n",
    "\n",
    "# Write dataframe to local csv using pandas to_csv() method\n",
    "police_shootings.to_csv('police_shootings.csv', encoding='utf-8')\n",
    "\n",
    "# Add file to your dataset using upload_files(). Replace the < > items with your dataset values\n",
    "api_client.upload_files('<YOUR_USERNAME>/<DATASET_TITLE>',['police_shootings.csv'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Update dataset\n",
    "\n",
    "# Add a file from an external source URL. In this example we'll use github. \n",
    "# Replace the < > items with your dataset values\n",
    "api_client.add_files_via_url('<YOUR_USERNAME>/<DATASET_TITLE>',{'shootings_of_police.csv': 'https://github.com/fivethirtyeight/data/blob/master/police-deaths/all_data.csv’})\n",
    "\n",
    "# For files added with add_files_via_url, fetch the latest version using the sync() method:\n",
    "api_client.sync_files('<YOUR_USERNAME>/<DATASET_TITLE>')\n",
    "                                                                \n",
    "# Use the update_dataset() method to update the metadata after dataset creation:\n",
    "api_client.update_dataset('<YOUR_USERNAME>/<DATASET_TITLE>', description='Dataset created to test out the python SDK functionality.', tags=['test', 'datacamp'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
